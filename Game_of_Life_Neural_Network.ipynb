{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Game_of_Life_Neural Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFGYTP1OYPI89zJnvFc71t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhihan/Conway-s-Game-of-Life-Neural-Network-/blob/master/Game_of_Life_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhE5KLl9z_9J",
        "colab_type": "text"
      },
      "source": [
        "# Conway's Game of Life\n",
        "## Rule of Conway's Game of Life\n",
        "The follwing states is copied from wikipedia page of [Conway's Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life):\n",
        "\n",
        "---\n",
        "The universe of the Game of Life is an infinite, two-dimensional orthogonal grid of square cells, each of which is in one of two possible states, alive or dead, (or populated and unpopulated, respectively). Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each step in time, the following transitions occur:\n",
        "\n",
        "* Any live cell with fewer than two live neighbours dies, as if by underpopulation.\n",
        "* Any live cell with two or three live neighbours lives on to the next generation.\n",
        "* Any live cell with more than three live neighbours dies, as if by overpopulation.\n",
        "* Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.\n",
        "\n",
        "---\n",
        "We can change rules by assigning the number of live neighbors (n_rebirth) which ensures the cell live and rebirth. For example, the original rules is n_rebirth =3: the cell can live or rebirth with 3 (n_rebirth) live neighbours, and the live cell which can still survive with 2 (n_rebirth-1) live neighbors. We can change the rules by setting n_rebirth to be between 2 and 8.\n",
        "## Goal\n",
        "The goal of this project is using deep learning methods to train the machine to :\n",
        "\n",
        "1. predict the pattern evolution without knowing the rule\n",
        "2. infere the rules from the given pattern evolutions which are produced by different rules (the model doesn't know the rules in the beginning). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxQrs5XsLTCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten, SimpleRNN, TimeDistributed, LSTM\n",
        "from keras.utils import np_utils\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWU02b4vJUhF",
        "colab_type": "text"
      },
      "source": [
        "Define the basic functions. The function life_step determines the next pattern with the current pattern and the given rules. The parameter \"edge\" determines how to deal with the behavior in the boundary. The original Conway's game of life have infinite rnage. For simplicity, here we define two scenario: \n",
        "\n",
        "1. edge = \"wrapped\": The boarders are wrapped:\n",
        "\n",
        " * The top row wraps to the bottom row.\n",
        " * The left side row wraps to the right side row (and vice versa).\n",
        " * The top-left cell wraps to the bottom-right cell (and vice versa).\n",
        "\n",
        "2. edge = \"die\" : The cells outside the boarder are considered as dead cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7diflKBRY3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def life_step(X, N_rebirth = 3, edge = 'wrapped' ):\n",
        "    assert (N_rebirth >1 or N_rebirth < 9 ), \"N_rebirth should be between[2,8]\"\n",
        "    assert (edge == 'wrapped' or edge == 'die'), \"x should be 'wrapped'(default) or 'die'\"\n",
        "    if( edge == 'wrapped' ):\n",
        "      live_neighbors = sum(np.roll(np.roll(X, i, 0), j, 1)\n",
        "                       for i in (-1, 0, 1) for j in (-1, 0, 1)\n",
        "                       if (i != 0 or j != 0))\n",
        "    elif( edge == 'die' ):\n",
        "      pad_width = {1: (1,0) , 0: (0,0) , -1: (0,1)}\n",
        "      slice0 = {1: slice(0,-1) , 0: slice(0,X.shape[0]) , -1: slice(1,X.shape[0]+1)}\n",
        "      slice1 = {1: slice(0,-1) , 0: slice(0,X.shape[1]) , -1: slice(1,X.shape[1]+1)}\n",
        "      live_neighbors = sum( np.pad(X,(pad_width[i],pad_width[j]) , mode='constant')[slice0[i],slice0[j]]\n",
        "                           for i in (-1, 0, 1) for j in (-1, 0, 1)\n",
        "                           if (i != 0 or j != 0))\n",
        "      \n",
        "    return (live_neighbors == N_rebirth) | (X & (live_neighbors == N_rebirth-1)).astype(int)\n",
        "def generate_frames(num_frames, board_shape=(100,100), prob_alive=0.15):\n",
        "    return np.array([\n",
        "        np.random.choice([False, True], size=board_shape, p=[1-prob_alive, prob_alive])\n",
        "        for _ in range(num_frames)\n",
        "    ]).astype(int)\n",
        "\n",
        "def render_frames(frame1, frame2):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(frame1.flatten().reshape(board_shape), cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(frame2.flatten().reshape(board_shape), cmap='gray')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKR-tZz6SM8V",
        "colab_type": "code",
        "outputId": "9c4cfc63-5445-478d-9ca1-0dff2e50bcc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "board_shape = (20, 20)\n",
        "board_size = board_shape[0] * board_shape[1]\n",
        "probability_alive = 0.15\n",
        "edge = 'wrapped'\n",
        "\n",
        "frames = generate_frames(10, board_shape=board_shape, prob_alive=probability_alive)\n",
        "print(frames.shape) # (num_frames, board_w, board_h)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 20, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqm6ZeJ-STbM",
        "colab_type": "code",
        "outputId": "0e1c7019-8547-4061-c328-1f1bf789cd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "render_frames(frames[1], life_step(frames[1],3,edge) )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvou39y-g4iT",
        "colab_type": "code",
        "outputId": "d3ac3c3e-e172-4536-a4fa-a5f36218cb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "board_shape = (20, 20)\n",
        "board_size = board_shape[0] * board_shape[1]\n",
        "probability_alive = 0.5\n",
        "edge = 'wrapped'\n",
        "\n",
        "frames = generate_frames(10, board_shape=board_shape, prob_alive=probability_alive)\n",
        "render_frames(frames[1], life_step(frames[1],3,edge) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LYksFtzLzWo",
        "colab_type": "text"
      },
      "source": [
        "Define the function generating the datasets, which contains a set of current pattern and the next pattern."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3iaGOCk_gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_input(X):\n",
        "    return X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
        "\n",
        "def generate_dataset(num_frames, board_shape, prob_alive, N_rebirth, edge = 'wrapped'):\n",
        "    X = generate_frames(num_frames, board_shape=board_shape, prob_alive=prob_alive)\n",
        "    X = reshape_input(X)\n",
        "    y = np.array([\n",
        "        life_step(frame,N_rebirth, edge) \n",
        "        for frame in X\n",
        "    ])\n",
        "    return X, y\n",
        "\n",
        "def generate_life_series(num_frames, board_shape, prob_alive, N_rebirth, edge = 'wrapped'):\n",
        "    X = np.array(np.random.choice([False, True], size=board_shape, p=[1-prob_alive, prob_alive])).astype(int)\n",
        "    X = [ X.reshape(X.shape[0], X.shape[1], 1) ]\n",
        "    \n",
        "    for i in range(num_frames-1):\n",
        "      X.append( life_step(X[-1],N_rebirth, edge) )\n",
        "\n",
        "    return np.array(X)\n",
        "\n",
        "train_size = 70000\n",
        "val_size   = 10000\n",
        "test_size  = 20000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY5IRxduyP-e",
        "colab_type": "code",
        "outputId": "9ffcf0a2-2be1-4b44-abe9-53888d8db5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "render_frames(X_series[2], life_step(X_series[1],N_rebirth=3,edge) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDn_Whu7U7vt",
        "colab_type": "text"
      },
      "source": [
        "Create the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJM89evllBI0",
        "colab_type": "code",
        "outputId": "d2f6d6c0-caef-433f-f49a-7e7c7cfc8469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Training Set:\")\n",
        "X_train, y_train = generate_dataset(train_size, board_shape, probability_alive, 3)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"Validation Set:\")\n",
        "X_val, y_val = generate_dataset(val_size, board_shape, probability_alive, 3)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(\"Test Set:\")\n",
        "X_test, y_test = generate_dataset(test_size, board_shape, probability_alive, 3)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "(70000, 20, 20, 1)\n",
            "(70000, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bco--NMea5iI",
        "colab_type": "code",
        "outputId": "8a1b4ee3-162d-4b44-d10b-2955ba3dcf30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Set:\n",
            "(10000, 20, 20, 1)\n",
            "(10000, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2zfh9NjbDw4",
        "colab_type": "code",
        "outputId": "b8126468-034f-48c0-88ba-ee6b9f6c69eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Set:\n",
            "(20000, 20, 20, 1)\n",
            "(20000, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duwg_S5hTKfc",
        "colab_type": "text"
      },
      "source": [
        "With the given sets of the initial patterns and the next generations,  building a model which can predict the next generations without knowing the rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ij0ih6y9WFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN Properties\n",
        "filters = 16\n",
        "kernel_size = (3, 3) # look at all 8 neighboring cells, plus itself\n",
        "strides = 1\n",
        "hidden_dims = 100\n",
        "input_shape = (board_shape[0] + 2, board_shape[1] + 2, 1) if edge == 'wrapped'   else (board_shape[0], board_shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SKhqAh9WA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(\n",
        "    filters, \n",
        "    kernel_size,\n",
        "    padding='valid',\n",
        "    activation='relu',\n",
        "    strides=strides,\n",
        "    input_shape=input_shape\n",
        "))\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCFG4HB9V8T",
        "colab_type": "code",
        "outputId": "086eeb9a-b022-408f-94cf-325de4d1fbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 16)        160       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20, 20, 100)       1700      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 20, 20, 1)         101       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 20, 20, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,961\n",
            "Trainable params: 1,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcbF3rPUP-2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSShzXT79ieA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_input(X):\n",
        "    return reshape_input(np.array([\n",
        "        np.pad(x.reshape(board_shape), (1,1), mode='wrap')\n",
        "        for x in X\n",
        "    ]))\n",
        "def train(model, X_train, y_train, X_val, y_val, batch_size=50, epochs=150, edge = 'wrapped' ):\n",
        "    X_train = pad_input(X_train) if edge == 'wrapped' else X_train\n",
        "    X_val = pad_input(X_val) if edge == 'wrapped' else X_val\n",
        "    history = model.fit(\n",
        "              X_train, y_train, \n",
        "              batch_size=batch_size, \n",
        "              epochs=epochs,\n",
        "              validation_data=(X_val, y_val)\n",
        "    )\n",
        "    return history\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AEuwNtH9msx",
        "colab_type": "code",
        "outputId": "581e9c99-ddd8-4c64-8283-134d9548fefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model, X_train[0:400], y_train[0:400], X_val[0:400], y_val[0:400])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 400 samples, validate on 400 samples\n",
            "Epoch 1/150\n",
            "400/400 [==============================] - 0s 541us/step - loss: 0.6720 - accuracy: 0.7440 - val_loss: 0.6326 - val_accuracy: 0.8810\n",
            "Epoch 2/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.6048 - accuracy: 0.8824 - val_loss: 0.5710 - val_accuracy: 0.8810\n",
            "Epoch 3/150\n",
            "400/400 [==============================] - 0s 137us/step - loss: 0.5470 - accuracy: 0.8824 - val_loss: 0.5184 - val_accuracy: 0.8810\n",
            "Epoch 4/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.4982 - accuracy: 0.8824 - val_loss: 0.4766 - val_accuracy: 0.8810\n",
            "Epoch 5/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.4612 - accuracy: 0.8824 - val_loss: 0.4456 - val_accuracy: 0.8810\n",
            "Epoch 6/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.4327 - accuracy: 0.8824 - val_loss: 0.4207 - val_accuracy: 0.8810\n",
            "Epoch 7/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.4088 - accuracy: 0.8824 - val_loss: 0.3982 - val_accuracy: 0.8810\n",
            "Epoch 8/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.3868 - accuracy: 0.8824 - val_loss: 0.3776 - val_accuracy: 0.8810\n",
            "Epoch 9/150\n",
            "400/400 [==============================] - 0s 141us/step - loss: 0.3668 - accuracy: 0.8824 - val_loss: 0.3592 - val_accuracy: 0.8810\n",
            "Epoch 10/150\n",
            "400/400 [==============================] - 0s 143us/step - loss: 0.3491 - accuracy: 0.8824 - val_loss: 0.3427 - val_accuracy: 0.8810\n",
            "Epoch 11/150\n",
            "400/400 [==============================] - 0s 127us/step - loss: 0.3333 - accuracy: 0.8824 - val_loss: 0.3281 - val_accuracy: 0.8810\n",
            "Epoch 12/150\n",
            "400/400 [==============================] - 0s 140us/step - loss: 0.3194 - accuracy: 0.8824 - val_loss: 0.3152 - val_accuracy: 0.8810\n",
            "Epoch 13/150\n",
            "400/400 [==============================] - 0s 156us/step - loss: 0.3070 - accuracy: 0.8824 - val_loss: 0.3034 - val_accuracy: 0.8810\n",
            "Epoch 14/150\n",
            "400/400 [==============================] - 0s 138us/step - loss: 0.2955 - accuracy: 0.8824 - val_loss: 0.2923 - val_accuracy: 0.8810\n",
            "Epoch 15/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.2844 - accuracy: 0.8824 - val_loss: 0.2812 - val_accuracy: 0.8810\n",
            "Epoch 16/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.2730 - accuracy: 0.8824 - val_loss: 0.2694 - val_accuracy: 0.8810\n",
            "Epoch 17/150\n",
            "400/400 [==============================] - 0s 139us/step - loss: 0.2607 - accuracy: 0.8824 - val_loss: 0.2563 - val_accuracy: 0.8810\n",
            "Epoch 18/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.2465 - accuracy: 0.8824 - val_loss: 0.2407 - val_accuracy: 0.8809\n",
            "Epoch 19/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.2303 - accuracy: 0.8826 - val_loss: 0.2236 - val_accuracy: 0.8824\n",
            "Epoch 20/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.2131 - accuracy: 0.8862 - val_loss: 0.2066 - val_accuracy: 0.8875\n",
            "Epoch 21/150\n",
            "400/400 [==============================] - 0s 126us/step - loss: 0.1968 - accuracy: 0.8960 - val_loss: 0.1919 - val_accuracy: 0.9005\n",
            "Epoch 22/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.1834 - accuracy: 0.9078 - val_loss: 0.1801 - val_accuracy: 0.9165\n",
            "Epoch 23/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.1725 - accuracy: 0.9238 - val_loss: 0.1705 - val_accuracy: 0.9273\n",
            "Epoch 24/150\n",
            "400/400 [==============================] - 0s 136us/step - loss: 0.1640 - accuracy: 0.9312 - val_loss: 0.1632 - val_accuracy: 0.9297\n",
            "Epoch 25/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.1575 - accuracy: 0.9334 - val_loss: 0.1576 - val_accuracy: 0.9344\n",
            "Epoch 26/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.1524 - accuracy: 0.9374 - val_loss: 0.1531 - val_accuracy: 0.9389\n",
            "Epoch 27/150\n",
            "400/400 [==============================] - 0s 148us/step - loss: 0.1485 - accuracy: 0.9425 - val_loss: 0.1496 - val_accuracy: 0.9428\n",
            "Epoch 28/150\n",
            "400/400 [==============================] - 0s 137us/step - loss: 0.1452 - accuracy: 0.9445 - val_loss: 0.1467 - val_accuracy: 0.9428\n",
            "Epoch 29/150\n",
            "400/400 [==============================] - 0s 156us/step - loss: 0.1426 - accuracy: 0.9445 - val_loss: 0.1443 - val_accuracy: 0.9428\n",
            "Epoch 30/150\n",
            "400/400 [==============================] - 0s 144us/step - loss: 0.1403 - accuracy: 0.9458 - val_loss: 0.1422 - val_accuracy: 0.9455\n",
            "Epoch 31/150\n",
            "400/400 [==============================] - 0s 151us/step - loss: 0.1384 - accuracy: 0.9472 - val_loss: 0.1402 - val_accuracy: 0.9455\n",
            "Epoch 32/150\n",
            "400/400 [==============================] - 0s 126us/step - loss: 0.1365 - accuracy: 0.9481 - val_loss: 0.1385 - val_accuracy: 0.9491\n",
            "Epoch 33/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.1348 - accuracy: 0.9505 - val_loss: 0.1368 - val_accuracy: 0.9491\n",
            "Epoch 34/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.1332 - accuracy: 0.9511 - val_loss: 0.1352 - val_accuracy: 0.9504\n",
            "Epoch 35/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.1316 - accuracy: 0.9518 - val_loss: 0.1337 - val_accuracy: 0.9504\n",
            "Epoch 36/150\n",
            "400/400 [==============================] - 0s 140us/step - loss: 0.1302 - accuracy: 0.9517 - val_loss: 0.1323 - val_accuracy: 0.9505\n",
            "Epoch 37/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.1288 - accuracy: 0.9525 - val_loss: 0.1308 - val_accuracy: 0.9517\n",
            "Epoch 38/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.1274 - accuracy: 0.9539 - val_loss: 0.1294 - val_accuracy: 0.9529\n",
            "Epoch 39/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.1259 - accuracy: 0.9544 - val_loss: 0.1277 - val_accuracy: 0.9542\n",
            "Epoch 40/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.1241 - accuracy: 0.9560 - val_loss: 0.1258 - val_accuracy: 0.9553\n",
            "Epoch 41/150\n",
            "400/400 [==============================] - 0s 143us/step - loss: 0.1222 - accuracy: 0.9573 - val_loss: 0.1239 - val_accuracy: 0.9566\n",
            "Epoch 42/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.1205 - accuracy: 0.9563 - val_loss: 0.1222 - val_accuracy: 0.9554\n",
            "Epoch 43/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.1188 - accuracy: 0.9579 - val_loss: 0.1204 - val_accuracy: 0.9581\n",
            "Epoch 44/150\n",
            "400/400 [==============================] - 0s 127us/step - loss: 0.1170 - accuracy: 0.9592 - val_loss: 0.1186 - val_accuracy: 0.9581\n",
            "Epoch 45/150\n",
            "400/400 [==============================] - 0s 147us/step - loss: 0.1154 - accuracy: 0.9592 - val_loss: 0.1170 - val_accuracy: 0.9581\n",
            "Epoch 46/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.1139 - accuracy: 0.9592 - val_loss: 0.1156 - val_accuracy: 0.9581\n",
            "Epoch 47/150\n",
            "400/400 [==============================] - 0s 141us/step - loss: 0.1124 - accuracy: 0.9588 - val_loss: 0.1142 - val_accuracy: 0.9581\n",
            "Epoch 48/150\n",
            "400/400 [==============================] - 0s 138us/step - loss: 0.1111 - accuracy: 0.9611 - val_loss: 0.1129 - val_accuracy: 0.9593\n",
            "Epoch 49/150\n",
            "400/400 [==============================] - 0s 149us/step - loss: 0.1098 - accuracy: 0.9614 - val_loss: 0.1114 - val_accuracy: 0.9594\n",
            "Epoch 50/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.1081 - accuracy: 0.9603 - val_loss: 0.1092 - val_accuracy: 0.9606\n",
            "Epoch 51/150\n",
            "400/400 [==============================] - 0s 140us/step - loss: 0.1055 - accuracy: 0.9616 - val_loss: 0.1062 - val_accuracy: 0.9606\n",
            "Epoch 52/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.1026 - accuracy: 0.9619 - val_loss: 0.1031 - val_accuracy: 0.9620\n",
            "Epoch 53/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0995 - accuracy: 0.9631 - val_loss: 0.1000 - val_accuracy: 0.9633\n",
            "Epoch 54/150\n",
            "400/400 [==============================] - 0s 127us/step - loss: 0.0964 - accuracy: 0.9654 - val_loss: 0.0969 - val_accuracy: 0.9659\n",
            "Epoch 55/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0937 - accuracy: 0.9667 - val_loss: 0.0946 - val_accuracy: 0.9659\n",
            "Epoch 56/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0916 - accuracy: 0.9670 - val_loss: 0.0926 - val_accuracy: 0.9659\n",
            "Epoch 57/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0897 - accuracy: 0.9678 - val_loss: 0.0910 - val_accuracy: 0.9673\n",
            "Epoch 58/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0884 - accuracy: 0.9682 - val_loss: 0.0896 - val_accuracy: 0.9673\n",
            "Epoch 59/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0870 - accuracy: 0.9692 - val_loss: 0.0883 - val_accuracy: 0.9686\n",
            "Epoch 60/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0857 - accuracy: 0.9695 - val_loss: 0.0870 - val_accuracy: 0.9686\n",
            "Epoch 61/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0845 - accuracy: 0.9696 - val_loss: 0.0857 - val_accuracy: 0.9697\n",
            "Epoch 62/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0832 - accuracy: 0.9707 - val_loss: 0.0844 - val_accuracy: 0.9710\n",
            "Epoch 63/150\n",
            "400/400 [==============================] - 0s 150us/step - loss: 0.0820 - accuracy: 0.9717 - val_loss: 0.0832 - val_accuracy: 0.9721\n",
            "Epoch 64/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0808 - accuracy: 0.9729 - val_loss: 0.0820 - val_accuracy: 0.9721\n",
            "Epoch 65/150\n",
            "400/400 [==============================] - 0s 143us/step - loss: 0.0796 - accuracy: 0.9729 - val_loss: 0.0807 - val_accuracy: 0.9721\n",
            "Epoch 66/150\n",
            "400/400 [==============================] - 0s 136us/step - loss: 0.0783 - accuracy: 0.9729 - val_loss: 0.0795 - val_accuracy: 0.9721\n",
            "Epoch 67/150\n",
            "400/400 [==============================] - 0s 154us/step - loss: 0.0771 - accuracy: 0.9729 - val_loss: 0.0783 - val_accuracy: 0.9721\n",
            "Epoch 68/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.0770 - val_accuracy: 0.9747\n",
            "Epoch 69/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 0.0756 - val_accuracy: 0.9748\n",
            "Epoch 70/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0733 - accuracy: 0.9753 - val_loss: 0.0742 - val_accuracy: 0.9748\n",
            "Epoch 71/150\n",
            "400/400 [==============================] - 0s 141us/step - loss: 0.0721 - accuracy: 0.9755 - val_loss: 0.0730 - val_accuracy: 0.9760\n",
            "Epoch 72/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0709 - accuracy: 0.9765 - val_loss: 0.0719 - val_accuracy: 0.9760\n",
            "Epoch 73/150\n",
            "400/400 [==============================] - 0s 159us/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 0.0708 - val_accuracy: 0.9760\n",
            "Epoch 74/150\n",
            "400/400 [==============================] - 0s 137us/step - loss: 0.0687 - accuracy: 0.9765 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 75/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0676 - accuracy: 0.9765 - val_loss: 0.0686 - val_accuracy: 0.9760\n",
            "Epoch 76/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0666 - accuracy: 0.9765 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 77/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0655 - accuracy: 0.9765 - val_loss: 0.0663 - val_accuracy: 0.9760\n",
            "Epoch 78/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0644 - accuracy: 0.9765 - val_loss: 0.0651 - val_accuracy: 0.9772\n",
            "Epoch 79/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
            "Epoch 80/150\n",
            "400/400 [==============================] - 0s 146us/step - loss: 0.0620 - accuracy: 0.9791 - val_loss: 0.0627 - val_accuracy: 0.9787\n",
            "Epoch 81/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.0614 - val_accuracy: 0.9787\n",
            "Epoch 82/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.0601 - val_accuracy: 0.9787\n",
            "Epoch 83/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0581 - accuracy: 0.9791 - val_loss: 0.0588 - val_accuracy: 0.9787\n",
            "Epoch 84/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0568 - accuracy: 0.9791 - val_loss: 0.0574 - val_accuracy: 0.9787\n",
            "Epoch 85/150\n",
            "400/400 [==============================] - 0s 156us/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.0561 - val_accuracy: 0.9787\n",
            "Epoch 86/150\n",
            "400/400 [==============================] - 0s 142us/step - loss: 0.0542 - accuracy: 0.9791 - val_loss: 0.0548 - val_accuracy: 0.9787\n",
            "Epoch 87/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0528 - accuracy: 0.9792 - val_loss: 0.0535 - val_accuracy: 0.9787\n",
            "Epoch 88/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0514 - accuracy: 0.9792 - val_loss: 0.0516 - val_accuracy: 0.9788\n",
            "Epoch 89/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0494 - accuracy: 0.9796 - val_loss: 0.0496 - val_accuracy: 0.9792\n",
            "Epoch 90/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0476 - accuracy: 0.9800 - val_loss: 0.0477 - val_accuracy: 0.9797\n",
            "Epoch 91/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0458 - accuracy: 0.9803 - val_loss: 0.0459 - val_accuracy: 0.9799\n",
            "Epoch 92/150\n",
            "400/400 [==============================] - 0s 138us/step - loss: 0.0440 - accuracy: 0.9806 - val_loss: 0.0440 - val_accuracy: 0.9804\n",
            "Epoch 93/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0423 - accuracy: 0.9811 - val_loss: 0.0422 - val_accuracy: 0.9810\n",
            "Epoch 94/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0405 - accuracy: 0.9817 - val_loss: 0.0406 - val_accuracy: 0.9812\n",
            "Epoch 95/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0389 - accuracy: 0.9825 - val_loss: 0.0389 - val_accuracy: 0.9827\n",
            "Epoch 96/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0373 - accuracy: 0.9844 - val_loss: 0.0373 - val_accuracy: 0.9844\n",
            "Epoch 97/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0358 - accuracy: 0.9854 - val_loss: 0.0358 - val_accuracy: 0.9852\n",
            "Epoch 98/150\n",
            "400/400 [==============================] - 0s 146us/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
            "Epoch 99/150\n",
            "400/400 [==============================] - 0s 136us/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 0.0328 - val_accuracy: 0.9879\n",
            "Epoch 100/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0313 - val_accuracy: 0.9914\n",
            "Epoch 101/150\n",
            "400/400 [==============================] - 0s 142us/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0298 - val_accuracy: 0.9922\n",
            "Epoch 102/150\n",
            "400/400 [==============================] - 0s 139us/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
            "Epoch 103/150\n",
            "400/400 [==============================] - 0s 151us/step - loss: 0.0268 - accuracy: 0.9954 - val_loss: 0.0266 - val_accuracy: 0.9957\n",
            "Epoch 104/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0253 - accuracy: 0.9967 - val_loss: 0.0251 - val_accuracy: 0.9970\n",
            "Epoch 105/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.0237 - val_accuracy: 0.9977\n",
            "Epoch 106/150\n",
            "400/400 [==============================] - 0s 127us/step - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.0225 - val_accuracy: 0.9980\n",
            "Epoch 107/150\n",
            "400/400 [==============================] - 0s 143us/step - loss: 0.0215 - accuracy: 0.9982 - val_loss: 0.0213 - val_accuracy: 0.9986\n",
            "Epoch 108/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0200 - accuracy: 0.9987 - val_loss: 0.0196 - val_accuracy: 0.9990\n",
            "Epoch 109/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0185 - accuracy: 0.9991 - val_loss: 0.0181 - val_accuracy: 0.9993\n",
            "Epoch 110/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.0169 - val_accuracy: 0.9994\n",
            "Epoch 111/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0160 - accuracy: 0.9995 - val_loss: 0.0158 - val_accuracy: 0.9995\n",
            "Epoch 112/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0150 - accuracy: 0.9996 - val_loss: 0.0148 - val_accuracy: 0.9996\n",
            "Epoch 113/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0141 - accuracy: 0.9998 - val_loss: 0.0140 - val_accuracy: 0.9998\n",
            "Epoch 114/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0133 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9999\n",
            "Epoch 115/150\n",
            "400/400 [==============================] - 0s 138us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "400/400 [==============================] - 0s 158us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "400/400 [==============================] - 0s 144us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "400/400 [==============================] - 0s 148us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "400/400 [==============================] - 0s 148us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "400/400 [==============================] - 0s 129us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "400/400 [==============================] - 0s 132us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "400/400 [==============================] - 0s 143us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "400/400 [==============================] - 0s 153us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "400/400 [==============================] - 0s 134us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "400/400 [==============================] - 0s 135us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "400/400 [==============================] - 0s 137us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "400/400 [==============================] - 0s 152us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "400/400 [==============================] - 0s 128us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "400/400 [==============================] - 0s 133us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "400/400 [==============================] - 0s 141us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "400/400 [==============================] - 0s 126us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "400/400 [==============================] - 0s 131us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "400/400 [==============================] - 0s 139us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "400/400 [==============================] - 0s 127us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "400/400 [==============================] - 0s 124us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "400/400 [==============================] - 0s 130us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exjYoL4MvCJR",
        "colab_type": "text"
      },
      "source": [
        "## Rules inference from pattern evolution of Game of Life.\n",
        "With the given sets of the pattern evolution of Game of Life with different rules, building a model which can infer the rules. This is essentially a time-series classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV06a3Nol3EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_life_series_classified(num_series_list, num_frames, board_shape, prob_alive, N_rebirth_list, edge = 'wrapped'):\n",
        "    assert ( len(num_series_list) == len(N_rebirth_list) ), \"N_rebirth_list should be equal to num_series_list\"    \n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for n_series, n_rebirth in zip(num_series_list, N_rebirth_list):    \n",
        "      for i_series in range(n_series):\n",
        "        XX = np.array(np.random.choice([False, True], size=board_shape, p=[1-prob_alive, prob_alive])).astype(int)\n",
        "        XX = [ XX.reshape(XX.shape[0], XX.shape[1], 1) ]\n",
        "        Y.append( n_rebirth )\n",
        "        for i in range(num_frames-1):\n",
        "          XX.append( life_step(XX[-1], n_rebirth, edge) )\n",
        "        X.append( XX )\n",
        "\n",
        "    return np.array(X),np.array(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kOr3CEAvigF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size_list = [1000,1000]\n",
        "num_frames = 20\n",
        "board_shape = (20,20)\n",
        "prob_alive = 0.15\n",
        "N_rebirth_list = [3,4]\n",
        "val_size_list = [200,200]\n",
        "test_size_list = [100,100]\n",
        "X_train, y_train = generate_life_series_classified(train_size_list, num_frames, board_shape, prob_alive, N_rebirth_list, edge = 'wrapped')\n",
        "X_val, y_val = generate_life_series_classified(val_size_list, num_frames, board_shape, prob_alive, N_rebirth_list, edge = 'wrapped')\n",
        "X_test, y_test = generate_life_series_classified(val_size_list, num_frames, board_shape, prob_alive, N_rebirth_list, edge = 'wrapped')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lswTAjKPK26L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "956c9a3a-eaf9-47b9-e2ab-b00cb3fa5cc4"
      },
      "source": [
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 20, 20, 20, 1) (400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dphMaHxeKcn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_syn( X , y ):\n",
        "  temp = list(zip(X, y)) \n",
        "  random.shuffle(temp) \n",
        "  X , y = zip(*temp)\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  return X,y\n",
        "\n",
        "X_train, y_train = shuffle_syn( X_train, y_train )\n",
        "X_val, y_val = shuffle_syn( X_val, y_val )\n",
        "X_test, y_test = shuffle_syn( X_test, y_test )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLwzjYFZh4Cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_OneHotEncoder():\n",
        "  def __init__(self):\n",
        "    self.__label_encoder = LabelEncoder()\n",
        "    self.__onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "  def fit_transform(self,y_train):\n",
        "    integer_encoded = self.__label_encoder.fit_transform(y_train)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = self.__onehot_encoder.fit_transform(integer_encoded)\n",
        "    return onehot_encoded\n",
        "\n",
        "  def transform(self,y_train):\n",
        "    integer_encoded = self.__label_encoder.transform(y_train)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = self.__onehot_encoder.transform(integer_encoded)\n",
        "    return onehot_encoded\n",
        "\n",
        "  def inverse_transform(self, transformed, from = 'onehot', to = 'class'):\n",
        "    if (from == 'onehot' and to == 'class'):\n",
        "      inverted = self.__label_encoder.inverse_transform([np.argmax(transformed[0, :])])\n",
        "    elif (from == 'label' and to == 'class'):\n",
        "      inverted = self.__label_encoder.inverse_transform( transformed )\n",
        "    elif (from == 'onehot' and to == 'label'):\n",
        "      inverted = np.argmax(transformed[0, :])\n",
        "    else:\n",
        "      raise ValueError('(from, to) must be (onehot,class),(label,class),(onehot,label)')\n",
        "    return inverted\n",
        "\n",
        "  def inverse_transform(self, y_train_label):\n",
        "    inverted = self.__label_encoder.inverse_transform( y_train_label )\n",
        "    return inverted \n",
        "\n",
        " # _label_encoder = LabelEncoder()\n",
        " # _onehot_encoder = OneHotEncoder(sparse=False)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5WHYS9ykDWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_encoder = My_OneHotEncoder()\n",
        "y_train_onehot = my_encoder.fit_transform(y_train)\n",
        "y_val_onehot = my_encoder.fit_transform(y_val)\n",
        "y_test_onehot = my_encoder.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrAJTWDuWZvB",
        "colab_type": "text"
      },
      "source": [
        "### Building CNNLSTM model for time-series classification\n",
        "https://machinelearningmastery.com/cnn-long-short-term-memory-networks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTsYBLPM9iYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN Properties\n",
        "filters = 32\n",
        "kernel_size = (3, 3) # look at all 8 neighboring cells, plus itself\n",
        "strides = 1\n",
        "hidden_dims = 100\n",
        "input_shape = (None ,board_shape[0] + 2, board_shape[1] + 2, 1) if edge == 'wrapped'   else (num_frames ,board_shape[0], board_shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO0SE-jG9V11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(filters, \n",
        "    kernel_size,\n",
        "    padding='valid',\n",
        "    activation='relu',\n",
        "    strides=strides,\n",
        "    input_shape=input_shape)))\n",
        "\n",
        "model.add(TimeDistributed(MaxPool2D( pool_size=(2, 2) )))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "# define RNN model\n",
        "#model.add(LSTM(units=10))\n",
        "#model.add(SimpleRNN(units=10))\n",
        "model.add(LSTM(units=10))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=hidden_dims,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=2, kernel_initializer='normal', activation='softmax' ))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXNNjzUV4LRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "42df34e6-f256-4a47-edd2-012762a07b26"
      },
      "source": [
        "model.build((None,) + input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_79 (TimeDis (None, None, 20, 20, 32)  320       \n",
            "_________________________________________________________________\n",
            "time_distributed_80 (TimeDis (None, None, 10, 10, 32)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_81 (TimeDis (None, None, 3200)        0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 10)                128440    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 130,062\n",
            "Trainable params: 130,062\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbM2wKjVvBdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_input_series(X):\n",
        "    return X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1)\n",
        "def pad_input(X):\n",
        "    return np.array([\n",
        "        np.pad(x.reshape(board_shape), (1,1), mode='wrap')\n",
        "        for XX in X for x in XX \n",
        "    ]).reshape( X.shape[0], X.shape[1],X.shape[2]+2, X.shape[3]+2, 1)\n",
        "def train(model, X_train, y_train_onehot, X_val, y_val_onehot, batch_size=50, epochs=100, edge = 'wrapped' ):\n",
        "    X_train = pad_input(X_train) if edge == 'wrapped' else X_train\n",
        "    X_val = pad_input(X_val) if edge == 'wrapped' else X_val\n",
        "    print(X_train.shape,X_val.shape)\n",
        "    history = model.fit(\n",
        "              X_train, y_train_onehot, \n",
        "              batch_size=batch_size, \n",
        "              epochs=epochs,\n",
        "              validation_data=(X_val, y_val_onehot)\n",
        "              )\n",
        "      \n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bwwSja4eJAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0f64a5d-ee0c-4463-b0d4-f966d9ecbf56"
      },
      "source": [
        "history = train(model, X_train, y_train_onehot, X_val, y_val_onehot)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 20, 22, 22, 1) (400, 20, 22, 22, 1)\n",
            "Train on 2000 samples, validate on 400 samples\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 2s 1ms/step - loss: 0.4686 - accuracy: 0.8370 - val_loss: 0.3302 - val_accuracy: 0.9850\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 2s 855us/step - loss: 0.1776 - accuracy: 0.9865 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 2s 878us/step - loss: 0.0511 - accuracy: 0.9900 - val_loss: 0.0232 - val_accuracy: 0.9875\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 2s 888us/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 0.0927 - val_accuracy: 0.9800\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 2s 844us/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.0507 - val_accuracy: 0.9850\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 2s 846us/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.0217 - val_accuracy: 0.9925\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 2s 903us/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 0.0137 - val_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 2s 850us/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.0224 - val_accuracy: 0.9925\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 2s 882us/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0220 - val_accuracy: 0.9950\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 2s 870us/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.0202 - val_accuracy: 0.9925\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 2s 854us/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0209 - val_accuracy: 0.9900\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 2s 900us/step - loss: 0.0089 - accuracy: 0.9960 - val_loss: 0.0114 - val_accuracy: 0.9925\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 2s 882us/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0092 - val_accuracy: 0.9925\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 2s 847us/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 2s 902us/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0086 - val_accuracy: 0.9950\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 2s 873us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 2s 855us/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 2s 870us/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 0.9900\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 2s 856us/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 2s 875us/step - loss: 6.3814e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 2s 905us/step - loss: 4.1699e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9975\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 2s 855us/step - loss: 3.5461e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9975\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 2s 843us/step - loss: 4.7184e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9950\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 2s 843us/step - loss: 5.6005e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9975\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 2s 868us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0069 - val_accuracy: 0.9950\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 2s 913us/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0274 - val_accuracy: 0.9925\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 2s 857us/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0115 - val_accuracy: 0.9950\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 2s 876us/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 0.0661 - val_accuracy: 0.9825\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 2s 869us/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0230 - val_accuracy: 0.9925\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 2s 853us/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 2s 839us/step - loss: 8.9696e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 2s 845us/step - loss: 3.7672e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9925\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 2s 847us/step - loss: 3.1994e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9950\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 2s 850us/step - loss: 3.4245e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 2s 877us/step - loss: 2.0557e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9975\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 2s 878us/step - loss: 1.6292e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 2s 873us/step - loss: 2.0220e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 2s 884us/step - loss: 2.9591e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9975\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 2s 870us/step - loss: 6.8636e-04 - accuracy: 0.9995 - val_loss: 0.0103 - val_accuracy: 0.9975\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 2s 878us/step - loss: 1.8905e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9950\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 2s 835us/step - loss: 1.2174e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9950\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 2s 884us/step - loss: 3.0994e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9925\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 2s 888us/step - loss: 2.1804e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9925\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 2s 856us/step - loss: 7.8924e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 2s 851us/step - loss: 9.9455e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 2s 856us/step - loss: 1.5263e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9950\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 2s 889us/step - loss: 6.0899e-05 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9950\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 2s 841us/step - loss: 8.1874e-05 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9925\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 5.9532e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9925\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 2s 893us/step - loss: 3.1020e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9950\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 2s 871us/step - loss: 5.3376e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9975\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 2s 891us/step - loss: 9.0768e-05 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9975\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 2s 864us/step - loss: 7.1461e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9975\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 2s 837us/step - loss: 9.9698e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9950\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 2s 878us/step - loss: 3.1844e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9950\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 2s 898us/step - loss: 6.0866e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9950\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 2s 849us/step - loss: 7.9184e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9950\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 2s 827us/step - loss: 5.7997e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9950\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 1.4937e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9925\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 2s 849us/step - loss: 4.5288e-05 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9925\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 2s 832us/step - loss: 2.9647e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9925\n",
            "Epoch 63/100\n",
            "2000/2000 [==============================] - 2s 862us/step - loss: 5.5074e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9950\n",
            "Epoch 64/100\n",
            "2000/2000 [==============================] - 2s 853us/step - loss: 3.8649e-05 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9950\n",
            "Epoch 65/100\n",
            "2000/2000 [==============================] - 2s 843us/step - loss: 4.6815e-05 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9950\n",
            "Epoch 66/100\n",
            "2000/2000 [==============================] - 2s 856us/step - loss: 3.5074e-05 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9950\n",
            "Epoch 67/100\n",
            "2000/2000 [==============================] - 2s 840us/step - loss: 1.2034e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9950\n",
            "Epoch 68/100\n",
            "2000/2000 [==============================] - 2s 837us/step - loss: 4.9164e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9950\n",
            "Epoch 69/100\n",
            "2000/2000 [==============================] - 2s 864us/step - loss: 3.2460e-05 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9950\n",
            "Epoch 70/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 5.6471e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9950\n",
            "Epoch 71/100\n",
            "2000/2000 [==============================] - 2s 843us/step - loss: 2.7083e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9950\n",
            "Epoch 72/100\n",
            "2000/2000 [==============================] - 2s 843us/step - loss: 6.9702e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "2000/2000 [==============================] - 2s 849us/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1219 - val_accuracy: 0.9750\n",
            "Epoch 74/100\n",
            "2000/2000 [==============================] - 2s 840us/step - loss: 0.0430 - accuracy: 0.9930 - val_loss: 0.0310 - val_accuracy: 0.9925\n",
            "Epoch 75/100\n",
            "2000/2000 [==============================] - 2s 877us/step - loss: 0.0186 - accuracy: 0.9960 - val_loss: 0.0206 - val_accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "2000/2000 [==============================] - 2s 882us/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0820 - val_accuracy: 0.9825\n",
            "Epoch 77/100\n",
            "2000/2000 [==============================] - 2s 832us/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0182 - val_accuracy: 0.9975\n",
            "Epoch 78/100\n",
            "2000/2000 [==============================] - 2s 844us/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0392 - val_accuracy: 0.9850\n",
            "Epoch 79/100\n",
            "2000/2000 [==============================] - 2s 860us/step - loss: 9.9830e-04 - accuracy: 1.0000 - val_loss: 9.5987e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "2000/2000 [==============================] - 2s 846us/step - loss: 4.2553e-04 - accuracy: 1.0000 - val_loss: 5.6878e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "2000/2000 [==============================] - 2s 885us/step - loss: 2.8584e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "2000/2000 [==============================] - 2s 859us/step - loss: 9.5042e-04 - accuracy: 0.9995 - val_loss: 2.8086e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "2000/2000 [==============================] - 2s 866us/step - loss: 6.2466e-04 - accuracy: 0.9995 - val_loss: 0.0127 - val_accuracy: 0.9925\n",
            "Epoch 84/100\n",
            "2000/2000 [==============================] - 2s 874us/step - loss: 1.9399e-04 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9925\n",
            "Epoch 85/100\n",
            "2000/2000 [==============================] - 2s 870us/step - loss: 2.9320e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9925\n",
            "Epoch 86/100\n",
            "2000/2000 [==============================] - 2s 856us/step - loss: 1.1062e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9925\n",
            "Epoch 87/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 1.1234e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "2000/2000 [==============================] - 2s 858us/step - loss: 1.2312e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
            "Epoch 89/100\n",
            "2000/2000 [==============================] - 2s 869us/step - loss: 1.2189e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
            "Epoch 90/100\n",
            "2000/2000 [==============================] - 2s 860us/step - loss: 7.0635e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "Epoch 91/100\n",
            "2000/2000 [==============================] - 2s 844us/step - loss: 5.0861e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9975\n",
            "Epoch 92/100\n",
            "2000/2000 [==============================] - 2s 852us/step - loss: 8.6984e-05 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9975\n",
            "Epoch 93/100\n",
            "2000/2000 [==============================] - 2s 875us/step - loss: 1.5541e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9975\n",
            "Epoch 94/100\n",
            "2000/2000 [==============================] - 2s 870us/step - loss: 9.4011e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9975\n",
            "Epoch 95/100\n",
            "2000/2000 [==============================] - 2s 862us/step - loss: 8.7491e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9975\n",
            "Epoch 96/100\n",
            "2000/2000 [==============================] - 2s 863us/step - loss: 5.0040e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9975\n",
            "Epoch 97/100\n",
            "2000/2000 [==============================] - 2s 877us/step - loss: 3.8195e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9975\n",
            "Epoch 98/100\n",
            "2000/2000 [==============================] - 2s 862us/step - loss: 5.8564e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9975\n",
            "Epoch 99/100\n",
            "2000/2000 [==============================] - 2s 850us/step - loss: 3.3505e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9975\n",
            "Epoch 100/100\n",
            "2000/2000 [==============================] - 2s 831us/step - loss: 5.3816e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0fSAH_NeIzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the function of plotting training history\n",
        "def show_train_history(train_history, train , validation):\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(train)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train','validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJzFuLJbvBRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ea5e7eb8-e466-4ad7-b7a4-449cf4e3a2cd"
      },
      "source": [
        "show_train_history( history , 'accuracy' , 'val_accuracy')"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHBKuK54zWPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_classes( pad_input(X_val) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHPWPw9IzLt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "0ca5edcf-9777-4758-a876-d1839f7fe4dd"
      },
      "source": [
        "pd.crosstab( y_val, prediction , rownames=['label'], colnames=['predict'])"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predict    0    1\n",
              "label            \n",
              "3        200    0\n",
              "4          1  199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONWmxdIzLku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ-mAg0fqT_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}